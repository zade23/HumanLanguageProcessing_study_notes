# 深度学习与人类语言处理

## 课程目标和规划

### 课程将会学习到：

- 深度学习与人类语言处理(Deep Learning for Human Language Processing)
- 自然语言处理(Natural Language Processing, NLP)

### 如何理解**人类语言处理**：

- 让机器**<u>听懂</u>**人说的话，看懂人写的句子
- 机器**<u>说出</u>**人听懂的话，写出人看得懂的句子

### 如何理解**自然语言**：

- **人类在自然而然的环境下发展出来的**用于沟通的语言就叫自然语言
- 与**自然语言**相反的就是**人造语言**
  - **中文，英文**就是**自然语言**
  - **Python，Java，C++**就是**人造语言**
  - 自然语言可以被<u>**说出来**</u>和<u>**写出来**</u>

### 那么这门课程之所以**不叫**<u>深度学习与自然语言处理</u>的原因是：

- 课程与传统的自然语言处理教学课程相比，在教学文本和语音的比例平衡为1:1（大部分NLP课程会将比例设置为9:1）
- 同时希望研究者明白，语音相关的内容中“**语音辨识(Speech Recognition)”**仅是整体部分的一个小分支，真正的语音领域非常的广阔（语音合成，声音克隆……）。

### 为什么(李宏毅)要重视语音这部分的内容？

因为，**很多语言完全没有文字，只有语音的交流。**

根据人类文字网在21世纪的统计，世界上有文字的语言只占总语言的**56%**。并且对即便具有文字的语言来讲，我们并不知道这些文字是否被广泛的应用。

## 人类的语言非常的复杂

以语音为例：

- **1s**的语音就有**16k**个采样点，每个采样点中有**256**个数值values

以文字为例：

- 人类最长的句子包含了**13955**个单词，理解这样一句话需要连贯所有前后信息

在所有人力语言处理的任务中，我们可以用6中**模型涵盖**所以内容：

1. **语音转文本**
2. **文本转文本**
3. **语音转语音**
4. **文本转语音**
5. **语音转语音所属种类**
6. **文本转文本所属种类**

以上**也是这门课程所有要讲的内容。**

在此提出一个假设：**[硬Train一发](https://www.youtube.com/watch?v=F1vek6ULo9w)**

**硬Train一发**：没有什么问题时不能通过深度学习模型训练拟合解决的，如果有……那只是**训练资料不够丰富和GPU不够多**而已。

## 语音转文本

### ASR：Automatic Speech Recognition

**传统语音识别模型**是非常复杂的模型，是多个模组拼接起来的整体，封装后的软件需要2GB的空间。其中每个整体飞复杂度很高，需要把每一部分都处理好才能够完成一个完整的语音辨识模型（附图片），其中包括：

- 声学模型（Acoustic）
- 语言模型（Language Model）
- 词典（Lexicon）
- ……

而现如今的方法直接使用一个**End2End模型**实现，以手机中的**声音转文字**模型为例，大小只有**80mb**

## 文本转语音

### TTS：Text-to-Speech Synthesis

（附图片：All the problem solved？）

优点：端到端的效果最终学到了**抑扬顿挫**（注：这是一种不可控的学习，虽然有了顿挫，但是或许不是我想要的结果）

缺点：几个简单的单词却不能完整的读出来（或文字缺失，或破音），但是对于包含了这些单词的长句却可以非常好的读出来。

## 声音转声音

### SS：Speech Separation

- **鸡尾酒会效应（cocktail party effect）**：在一个嘈杂的场景下，人类可以轻易的区分自己想要关心的内容和听到想要听到的人所说的话

机器想要达到这样的效果没有人类那样方便。

传统方法是对完整的音频波形采取**傅里叶变换（Fourier Transformer）**进行时域和频域的分析，然而深度学习的“魅力”在于，**“硬Train一发”**也解决了声音分离的问题。

### VC：Voice Conversion

在变声器实现上，**“硬Train一发”**的思路是：让说话人A和说话人B说**同样的一句话**，一直说上成百上千句以后，让机器学习二者在不同波段上的转换。

上述的思路实现下来也并不困难。

但是，让两个人说**同样的一句话**的难点在于，被克隆声音者一般都是不易获取音频信息的（被克隆声音者一般都是明星、声优、公众人物……），那么能否仅通过被克隆者的音频数据来拷贝他的音色特征去实现声音的转换？这才是VC的难点所在。

## 语音转语音所属种类

### SR：Speaker Recognition

任务：区分一段音频中到底有几个人再说话。

### KS：Keyword Spotting

检测音频输入过程中是否出现过某些**关键词**

- 语音唤醒（小爱同学~、hey Siri~）

## 从Bert开始文本转文本的内容学习

Bert家族（图片）都是《芝麻街》的人物：



可以进行这几类模型的参数对比（现如今ChatGPT正火，ChatGPT是GPT-3.5模型，参数之大可想而知）：



### 非线性的文本生成

自动生成：

Autoregressive：从前向后顺序生成

非自动生成：

Non-autoregressive：先生成**关键词**，有**关键词**再找**主语**，再找**主语**和**关键词**之间的**关系**

各种各样的应用场景：

- 翻译软件
- 摘要总结
- 聊天机器人
- 问答系统
- ……

或者仅仅一个**ChatGPT**就可以实现全部内容……

（例：通过**树模型**实现的**语法分析**）





本节课程在文本转文本内容上会专注在**问答系统**这一方面

主要因为这方面是比较重要的，其次“一法通，万法通”。

## Meta Learning = Learn to Learn

更加泛化性的学习：

如何通过学习一种语言从而应用到更加高效的学习新的语言

### 风格转换模型

Learning from Unpaired Data：只给机器两个不同风格的数据，不通过任何标注的方法让机器自己学习观察两个数据的风格差异，最终实现二者进行转换的模型。（我理解这也是生成类模型）

### 知识图谱模型



### 信息安全

广告检测和有毒数据监测

(图片)

### 可解释性人工智能

解决对于结果的可解释性，而不是单纯的“黑箱”得出的结论。