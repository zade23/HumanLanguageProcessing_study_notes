# 语音识别

语音辨识在五十年前被认为是不可能实现的事情，因为在这样的。

（大名鼎鼎的电晶体发明者J.R.Pierce认为这是不可能实现的任务）

（图片）

而现如今，每一部手机都可以实现语音识别的任务。

语音向量被表示为



## 语音识别的辨识单位

### Token

#### Phoneme

通过将Phoneme转换成Lexicon，再由Lexicon转换为Token的方法，最终实现了语音的识别工作。

这样的方法在深度学习还不流行的时代是非常常规的选择。

**技术难点**：Lexicon需要有语言学基础的专家进行先行的标注，也就是**做音标**

#### Grapheme

以英文为例：

Grapheme是包含了26个英文字母外加空格和标点等符号的最小书写单元。

若是用中文：

Grapheme直接将一个中文单字作为一个最小单元，中文包含了一万多个单字，常用的字在四千多左右。

这样的方法是深度学习能够使用的方法，不需要语言学习进行音标标注，只需要进行大量的数据训练就可以解决问题。

**技术难点**：在对多音字的发音上，模型需要通过上下文以及非常多的学习后，才能理解多音字在不同情景下的发音。类似的还有发音时情感的抑扬顿挫。

（图片）

#### Word

首先，用Word作为语音识别的辨识单位往往不是最好的选择。（最好的例子：**“土耳其语”**是通过在一个单词中不断加后缀的方式从而形成新的单词）

（图片）

#### Morpheme（词素）

解释：一种语言中可以传达意思的最小单位。

从结构上讲：比Word小，比Grapheme大的单位

Unbreakable -> un + break + able

这样的好处是可以高效的让机器学习到这种新语言的特征

**技术难点**：同样需要对数据的预处理工作，即语言学家进行词素标注或统计大量的单词数据进行词素的总结（统计学在小样本下进行的统计还有一点的误差存在）

#### Bytes

直接用byte当做单位，将每一种不同语言的符号用UTF-8编码的方法进行表示。

例如：听到一段日文，即输出日文对应的UTF-8编码；听到一段中文，即输出中文对应的UTF-8编码。最后通过查表的方式得到语种的分类。

（图片）

#### 总结

截止2019年，语音识别工作采用的Token统计：

（图片）

#### 其他的想法

（图片）

1. 声音->词嵌入
2. 声音->翻译结果
3. 声音指令->完成指令任务
4. 声音->阅读理解 （可以是上一个任务的升级）

## Acoustic Feature（声学特征）

（24:37分开始）

这一部分对应了语音输入的部分

输入一段声音信号，声音信号的长度length是T，高度(维度)是d。

（图片）

一个音框大概含有25ms

一段声音信号作为输入，每1s的语音会转化出100个Frames，每个Frames可能包含的信息是：

- 400个采样点(16KHz标准)
- 39维的 MFCC信息(MFCC是语音信号处理中的一种特征提取方法，全称为Mel频率倒谱系数)
- 80维的Filter Bank Output(滤波器组输出)

每个音框每一次大约移动10ms，所以其实每个连续音框之间是有重叠的

### 声音特征如何被提取

下面的一张图用来演示，声音信号的特征是如何被提取出来的。

（图片）

第一步：将波形提取出来进行离散傅里叶变换得到频谱图。

说明：

这一步是非常有必要的，因为就算是非常近似的波形，实际上听到的声音效果也是非常不同的。

然而通过波形特征进行离散傅里叶变换转换的频谱图会包含更多的信息，如果是语音领域的专家，是能够从频谱图中知道这段声音信号说的是什么内容(元音和辅音有对应的频谱图形)。

因此，用频谱图做语音识别工作是传统的思路之一。因为，人尚能通过观察频谱图进行读音的识别，作为机器学习相关特征走势，也可以识别对应波形的语音讯息到底是什么。

但其实频谱图并非是做语音识别工作的主流。

#### Filter Bank（滤波器组）

（图片，如何理解滤波器组输出？）

得到对应的频谱图后，通过一些滤波器模块的组合进行滤波处理，再通过取Log(为什么？)的方式加上DCT(什么是DCT)，最终得到MFCC信息。

至此是一个完整的声学特征提取过程。

（图片，一套完整的流程）

下面是截止2019年，声学特征提取的几类主流方式：

（图片，滤波方式饼状图）

2010年之前，MFCC一直是主流。

2014年之后深度学习的方式渐渐取代了传统的MFCC，将来MFCC也会越来越少。

如今，直接使用Filter Bank Output的方式就足够了

## 语料库

1. TIMIT
2. WSJ
3. Switchboard
4. Librispeech
5. Fisher

以及，将数据包含的信息数同等代换之后的图像数据集与音频数据集对比。

(李宏毅：听说真正在这些企业用于做训练资料的数据其实是文献上标注的10到20倍)

（图片，语料库时长对比）

## 提前预告：两类模型来处理音频信号

### Sequence-to-Sequence

序列到序列的学习

### HMM

隐马尔科夫模型

### 预计介绍五类模型

1. Listen，Attend，and Spell（LAS）
2. Connectionist Temporal Classification（CTC）
3. RNN Transducer（RNN-T）
4. Neural Transducer
5. Monotonic Chunkwise Attention